{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.fda import FDA_source_to_target\n",
    "from utils.aug import ExtCompose, ExtTransforms, ExtRandomHorizontalFlip , ExtScale , ExtRandomCrop, ExtGaussianBlur, ExtColorJitter, ExtResize, ExtToV2Tensor\n",
    "from datasets.cityscapes import CityScapes\n",
    "from datasets.GTA5 import GTA5\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDA Style Transfer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.05\n",
    "h = 512\n",
    "w = 1024\n",
    "b = (  np.floor(np.amin((h,w))*beta)  ).astype(int)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  dataset\n"
     ]
    }
   ],
   "source": [
    "standard_transformations = ExtCompose([ExtScale(0.5,interpolation=Image.Resampling.BILINEAR), ExtToV2Tensor()])\n",
    "transformations = ExtCompose([ExtResize((512,1024)), ExtToV2Tensor()])\n",
    "target_transformations = standard_transformations\n",
    "\n",
    "train_dataset = GTA5(root='dataset',transforms=transformations)\n",
    "target_dataset_train = CityScapes(split='train',transforms=target_transformations)\n",
    "\n",
    "source_dataloader_train = DataLoader(train_dataset,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                num_workers=1,\n",
    "                pin_memory=False,\n",
    "                drop_last=True)\n",
    "target_dataloader_train = DataLoader(target_dataset_train,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                num_workers=1,\n",
    "                pin_memory=False,\n",
    "                drop_last=True)\n",
    "\n",
    "for i, (source_data, target_data) in enumerate(zip(source_dataloader_train,target_dataloader_train)):\n",
    "  \n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "    source_data,source_label = source_data\n",
    "    target_data,_ = target_data\n",
    "    source_data = source_data.cuda()\n",
    "    source_label = source_label.long().cuda()\n",
    "    target_data = target_data.cuda()\n",
    "\n",
    "    t_source_data = FDA_source_to_target(source_data, target_data, beta=beta)\n",
    "\n",
    "    # Visualize the image (.png) and the transformed image (.jpg)\n",
    "    Image.fromarray(target_data.detach().cpu().numpy().astype('uint8')[0].transpose(1, 2, 0)).show()\n",
    "    Image.fromarray(source_data.detach().cpu().numpy().astype('uint8')[0].transpose(1, 2, 0)).show()\n",
    "    Image.fromarray(t_source_data.detach().cpu().numpy().astype('uint8')[0].transpose(1, 2, 0)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strong Data Augmentation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented image 1\n",
      "Augmented image 2\n",
      "Augmented image 3\n",
      "Augmented image 4\n",
      "Augmented image 5\n",
      "Augmented image 6\n",
      "Augmented image 7\n",
      "Augmented image 8\n",
      "Augmented image 9\n",
      "Augmented image 10\n",
      "Augmented image 11\n",
      "Augmented image 12\n",
      "Augmented image 13\n",
      "Augmented image 14\n",
      "Augmented image 15\n",
      "Augmented image 16\n",
      "Augmented image 17\n",
      "Augmented image 18\n",
      "Augmented image 19\n",
      "Augmented image 20\n",
      "Augmented image 21\n"
     ]
    }
   ],
   "source": [
    "size = (512,1024)\n",
    "transformations = ExtCompose([\n",
    "                ExtScale(random.choice([0.75,1,1.25,1.5,1.75,2]),interpolation=Image.Resampling.BILINEAR),\n",
    "                ExtRandomCrop(size),\n",
    "                ExtRandomHorizontalFlip(),\n",
    "                ExtGaussianBlur(p=0.5, radius=1),\n",
    "                ExtColorJitter(p=0.5, brightness=0.2, contrast=0.1, saturation=0.1, hue=0.2),\n",
    "                ExtToV2Tensor()])\n",
    "train_dataset = GTA5(root='dataset',transforms=transformations)\n",
    "source_dataloader_train = DataLoader(train_dataset,\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                num_workers=1,\n",
    "                pin_memory=False,\n",
    "                drop_last=True)\n",
    "\n",
    "for i, (source_data, source_label) in enumerate(source_dataloader_train):\n",
    "  \n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "    print(f'Augmented image {i+1}')\n",
    "    # Visualize the image (.png) and the transformed image (.jpg)\n",
    "    Image.fromarray(source_data.detach().cpu().numpy().astype('uint8')[0].transpose(1, 2, 0)).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
